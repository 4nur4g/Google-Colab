{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ktrain Model Deployment",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs33rA4mOtLT",
        "colab_type": "text"
      },
      "source": [
        "# ***Model - Ktrain***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo8n8Nxd1hbc",
        "colab_type": "text"
      },
      "source": [
        "### ***Installing Packages***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyF93bmF1Kxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78999876-1a03-423c-f94b-db8ed356043c"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ktrain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/40/bb9a34bfd0e8e6f6f763fb3f97b61734b1a868fce66ef7e8ab65a71120de/ktrain-0.7.2.tar.gz (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 35.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.21.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.1.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.25.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.1.22)\n",
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.14.1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.39)\n",
            "Collecting cchardet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/4e/847feebfc3e71c773b23ee06c74687b8c50a5a6d6aaff452a0a4f4eb9a32/cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 59.6MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.4)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (19.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3->ktrain) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3->ktrain) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->ktrain) (2018.9)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert->ktrain) (2.2.5)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->ktrain) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.3->ktrain) (4.4.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.10.3)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.3.0)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->ktrain) (42.0.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert->ktrain) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert->ktrain) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert->ktrain) (1.1.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh->ktrain) (0.46)\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: ktrain, keras-bert, langdetect, networkx, seqeval, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.7.2-cp36-none-any.whl size=113492 sha256=54a8d94e5875e605a24f316d6183c3e962d229ef32530f60ff870647c48d928c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/db/bd/fb2cb12563e8a7e5ef04f99cc9014bc0e509f1bb3834e6ee5d\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=9ae101f817381c2f6efc1dc608a283f04564eaf06c3e66c060da1d573daf4fee\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=b6d71386aea1802e729f2cda253529f58c4c933d44c3929d9c85ff6f501a6e24\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=1496654fec7edbdb21a0c39d46942e0ac392a5595707882a3cbf6f5bdb6d5bc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=3b320defaa276308ea73dd297345812892ce55cdb9e598099f0d95c3249dab48\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=ae175e6a5c325f44b9af5006c6a1ceb8a93dfddce9b1979c3d5d0d98256b418e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=d48c7a81037f2f33edb219964db3f76e16e8d638efd7433d74b576d7a9c561ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=2633b73c4eb51b8a354a0af2219e5f95faeff9f4c514d5640c9c380990eff742\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=6a3943427df7958f448030e86903a49dcef3fde399011a7cbd0296c9071bb6a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=41ce54a2727b8ea4650b4bb407b92672feb92241923379c24e3595a5b7b00b56\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=8c592c01096e46ffdc2ba94905830fd69235b2a15488415abeb070bb2a8bd439\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=0eca8818a352ba2b84c277d5f6969112745ec885737681b0f528877a74a37fc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built ktrain keras-bert langdetect networkx seqeval keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, networkx, seqeval, ktrain\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "Successfully installed cchardet-2.1.5 keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0 ktrain-0.7.2 langdetect-1.0.7 networkx-2.3 seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6OEjZP21m-Y",
        "colab_type": "text"
      },
      "source": [
        "### ***Importing packages***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHKXHgTQ1boY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.backend import get_session, set_session\n",
        "from tensorflow.keras import backend as K\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wx7Fxz1Ppr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5440e19f-bfc4-4c68-a29c-fa511de178f3"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snB7NnQz1yeY",
        "colab_type": "text"
      },
      "source": [
        "### ***Training***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWUpD6dtPA-Y",
        "colab_type": "code",
        "outputId": "9ec3583b-e1e9-40ab-d25c-049521550c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "DATA_PATH = 'Category.csv'\n",
        "NUM_WORDS = 50000\n",
        "MAXLEN = 25000\n",
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(DATA_PATH,\n",
        "                      'Sentences',\n",
        "                      label_columns = cat_dummies.columns[:-1],\n",
        "                      val_filepath=None, \n",
        "                      max_features=NUM_WORDS,\n",
        "                      maxlen=MAXLEN,\n",
        "                      encoding= 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language: en\n",
            "Word Counts: 40027\n",
            "Nrows: 25413\n",
            "25413 train sequences\n",
            "Average train sequence length: 24\n",
            "x_train shape: (25413,25000)\n",
            "y_train shape: (25413,151)\n",
            "2824 test sequences\n",
            "Average test sequence length: 23\n",
            "x_test shape: (2824,25000)\n",
            "y_test shape: (2824,151)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_apxjcgqOvdb",
        "colab_type": "code",
        "outputId": "5ffdc2e9-a4d0-445c-dff1-381764a52304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model = text.text_classifier('fasttext', (x_train, y_train), preproc=preproc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "compiling word ID features...\n",
            "maxlen is 25000\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6wWKcLwgVGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqhOCierOq2F",
        "colab_type": "code",
        "outputId": "b560b48d-7748-4b7e-9586-88b225ba1710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "learner.lr_find()\n",
        "learner.lr_plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n",
            "Train on 25413 samples\n",
            "Epoch 1/1024\n",
            "25413/25413 [==============================] - 56s 2ms/sample - loss: 5.2551 - acc: 0.0073\n",
            "Epoch 2/1024\n",
            "25413/25413 [==============================] - 56s 2ms/sample - loss: 4.9004 - acc: 0.0436\n",
            "Epoch 3/1024\n",
            " 8384/25413 [========>.....................] - ETA: 37s - loss: 9.2332 - acc: 0.0064\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAENCAYAAAAIbA6TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgnQ011TV7ej",
        "colab_type": "code",
        "outputId": "18e1dbf6-d165-4e23-ff25-fa6a546c23c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.autofit(0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.001...\n",
            "Train on 25413 samples, validate on 2824 samples\n",
            "Epoch 1/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 4.8633 - acc: 0.0516 - val_loss: 4.2578 - val_acc: 0.2663\n",
            "Epoch 2/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 4.1159 - acc: 0.1599 - val_loss: 3.2442 - val_acc: 0.4246\n",
            "Epoch 3/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 3.4800 - acc: 0.2516 - val_loss: 2.6075 - val_acc: 0.5004\n",
            "Epoch 4/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 3.0776 - acc: 0.3081 - val_loss: 2.2776 - val_acc: 0.5340\n",
            "Epoch 5/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.8008 - acc: 0.3543 - val_loss: 2.0829 - val_acc: 0.5535\n",
            "Epoch 6/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.6162 - acc: 0.3815 - val_loss: 1.9494 - val_acc: 0.5740\n",
            "Epoch 7/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.4505 - acc: 0.4099 - val_loss: 1.8717 - val_acc: 0.5864\n",
            "Epoch 8/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.3333 - acc: 0.4315 - val_loss: 1.8010 - val_acc: 0.5935\n",
            "Epoch 9/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.2274 - acc: 0.4476 - val_loss: 1.7525 - val_acc: 0.5988\n",
            "Epoch 10/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.1430 - acc: 0.4641 - val_loss: 1.7096 - val_acc: 0.6073\n",
            "Epoch 11/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 2.0560 - acc: 0.4824 - val_loss: 1.6760 - val_acc: 0.6119\n",
            "Epoch 12/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.9807 - acc: 0.4942 - val_loss: 1.6490 - val_acc: 0.6211\n",
            "Epoch 13/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.9132 - acc: 0.5105 - val_loss: 1.6286 - val_acc: 0.6328\n",
            "Epoch 14/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.8547 - acc: 0.5219 - val_loss: 1.6071 - val_acc: 0.6300\n",
            "Epoch 15/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.8042 - acc: 0.5339 - val_loss: 1.5837 - val_acc: 0.6367\n",
            "Epoch 16/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.7569 - acc: 0.5448 - val_loss: 1.5747 - val_acc: 0.6349\n",
            "Epoch 17/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.7134 - acc: 0.5542 - val_loss: 1.5638 - val_acc: 0.6448\n",
            "Epoch 18/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.6608 - acc: 0.5622 - val_loss: 1.5618 - val_acc: 0.6466\n",
            "Epoch 19/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.6140 - acc: 0.5745 - val_loss: 1.5522 - val_acc: 0.6480\n",
            "Epoch 20/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.5819 - acc: 0.5856 - val_loss: 1.5421 - val_acc: 0.6462\n",
            "Epoch 21/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.5562 - acc: 0.5925 - val_loss: 1.5360 - val_acc: 0.6604\n",
            "Epoch 22/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.5212 - acc: 0.5985 - val_loss: 1.5442 - val_acc: 0.6462\n",
            "Epoch 23/1024\n",
            "25408/25413 [============================>.] - ETA: 0s - loss: 1.4989 - acc: 0.5994\n",
            "Epoch 00023: Reducing Max LR on Plateau: new max lr will be 0.0005 (if not early_stopping).\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.4991 - acc: 0.5994 - val_loss: 1.5370 - val_acc: 0.6516\n",
            "Epoch 24/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.4332 - acc: 0.6178 - val_loss: 1.5344 - val_acc: 0.6569\n",
            "Epoch 25/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.4002 - acc: 0.6260 - val_loss: 1.5222 - val_acc: 0.6590\n",
            "Epoch 26/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.3710 - acc: 0.6330 - val_loss: 1.5214 - val_acc: 0.6593\n",
            "Epoch 27/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.3455 - acc: 0.6385 - val_loss: 1.5213 - val_acc: 0.6562\n",
            "Epoch 28/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.3286 - acc: 0.6423 - val_loss: 1.5177 - val_acc: 0.6668\n",
            "Epoch 29/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.2940 - acc: 0.6533 - val_loss: 1.5209 - val_acc: 0.6632\n",
            "Epoch 30/1024\n",
            "25408/25413 [============================>.] - ETA: 0s - loss: 1.2768 - acc: 0.6530\n",
            "Epoch 00030: Reducing Max LR on Plateau: new max lr will be 0.00025 (if not early_stopping).\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.2771 - acc: 0.6529 - val_loss: 1.5210 - val_acc: 0.6650\n",
            "Epoch 31/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.2454 - acc: 0.6639 - val_loss: 1.5165 - val_acc: 0.6678\n",
            "Epoch 32/1024\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.2304 - acc: 0.6712 - val_loss: 1.5187 - val_acc: 0.6675\n",
            "Epoch 33/1024\n",
            "25408/25413 [============================>.] - ETA: 0s - loss: 1.1979 - acc: 0.6722\n",
            "Epoch 00033: Reducing Max LR on Plateau: new max lr will be 0.000125 (if not early_stopping).\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.1981 - acc: 0.6721 - val_loss: 1.5174 - val_acc: 0.6696\n",
            "Epoch 34/1024\n",
            "25413/25413 [==============================] - 57s 2ms/sample - loss: 1.1889 - acc: 0.6788 - val_loss: 1.5179 - val_acc: 0.6675\n",
            "Epoch 35/1024\n",
            "25408/25413 [============================>.] - ETA: 0s - loss: 1.1891 - acc: 0.6807\n",
            "Epoch 00035: Reducing Max LR on Plateau: new max lr will be 6.25e-05 (if not early_stopping).\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.1896 - acc: 0.6806 - val_loss: 1.5201 - val_acc: 0.6686\n",
            "Epoch 36/1024\n",
            "25408/25413 [============================>.] - ETA: 0s - loss: 1.1582 - acc: 0.6877Restoring model weights from the end of the best epoch.\n",
            "25413/25413 [==============================] - 58s 2ms/sample - loss: 1.1586 - acc: 0.6876 - val_loss: 1.5200 - val_acc: 0.6682\n",
            "Epoch 00036: early stopping\n",
            "Weights from best epoch have been loaded into model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e50a50828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tlQSezWvm9w",
        "colab_type": "text"
      },
      "source": [
        "#### **Saving Model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGBGdQki6jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uenvYwRV-gk",
        "colab_type": "code",
        "outputId": "7fabf88c-3d74-451b-de59-4be1b842eb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictor.save('category')\n",
        "print('*********************************MODEL SAVED***************************************************')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*********************************MODEL SAVED***************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6otphUh61C3r",
        "colab_type": "text"
      },
      "source": [
        "#### **Loading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpQ5smBRV-fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the model and assign it to the predictor\n",
        "loaded_model = ktrain.load_predictor('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794wx1c7iyxG",
        "colab_type": "text"
      },
      "source": [
        "## **Saving and Loading Model - Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw3E1Umui4ja",
        "colab_type": "code",
        "outputId": "c123f435-efaf-4a4f-e872-8899a9341a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Saving Model\n",
        "model_json = learner.model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "learner.model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5QrV4lexozV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cat_init():\n",
        "  # Load model json file\n",
        "  json_file = open('/content/drive/My Drive/Models/cat_model.json','r')\n",
        "\n",
        "  # Load Ktrain preproc file\n",
        "  features = pickle.load(open('/content/drive/My Drive/Models/cat_model.preproc', 'rb'))\n",
        "  \n",
        "  # Session\n",
        "  sess =K.get_session()\n",
        "  graph = tf.get_default_graph()\n",
        "\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "  loaded_model.load_weights(\"/content/drive/My Drive/Models/cat_model.h5\")\n",
        "  print(\"Model Loaded from disk\")\n",
        "\n",
        "  #compile and evaluate loaded model\n",
        "  loaded_model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['acc'])\n",
        "  return loaded_model,graph,sess,features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUtgP2LezmOz",
        "colab_type": "code",
        "outputId": "f5568e81-1ad6-4efe-be32-5c8a0794ec32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "global cat_graph, cat_model, cat_sess, cat_features\n",
        "cat_model, cat_graph, cat_sess, cat_features = cat_init()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Keras version: 2.2.4-tf\n",
            "Model Loaded from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSo9w3aDzpO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertText(text):\n",
        "\tvector_text = cat_features.preprocess([text])\n",
        "\treturn vector_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJFxo6rCz3mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = 'i want to install ms office'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnmxC5D5zskG",
        "colab_type": "code",
        "outputId": "0fd7c39a-1ebc-4817-aa73-f313e4eda1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vec_query = convertText(query)\n",
        "cat_classes = {0:'Hardware',1:'Network',2:'SAP Authorizations',3:'Software'}\n",
        "\n",
        "# Category prediction\n",
        "with cat_graph.as_default():\n",
        "  set_session(cat_sess)\n",
        "  vec_cat = cat_model.predict(vec_query)\n",
        "\n",
        "cat_index = vec_cat[0].argmax(axis=0)\n",
        "\n",
        "category = cat_classes[cat_index]\n",
        "print({'Category':category})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Category': 'Software'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--chuRVo2BAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}